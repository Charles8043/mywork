{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據集內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 轉一下我們的資料格式:\n",
    "\n",
    "### (28,28) --> (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1) / 255\n",
    "x_test = x_test.reshape(10000,28,28,1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# dense：全連結神經層\n",
    "# Conv2D的2D代表每個「記分板(kernal)」的維度 \n",
    "# 如果輸入的是2D圖片(無論是灰階或是彩色)都是用Conv2D，輸入的是3D的立體圖片用Conv3D\n",
    "# Conv2D輸入的是三維數據(width, height, channels)；Conv3D輸入的是四維數據(width, height, depth, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. 打造函數學習機(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), padding = \"same\", \n",
    "                 input_shape =(28,28,1), \n",
    "                 activation = \"relu\" )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出16個 28x28 矩陣\n",
    "### 事實上是(28,28,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))# (14,14,16) 原本為28x28,16張記分板，每個都切成2x2, 剩下14x14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3,3), padding='same',\n",
    "                activation='relu')) # output = (14,14,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))# output (7,7,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3,3), padding = \"same\", activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(54,activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation = \"softmax\")) #10個數字, softmax 加起來為1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看一下我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 54)                31158     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                550       \n",
      "=================================================================\n",
      "Total params: 55,004\n",
      "Trainable params: 55,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"mse\", optimizer = SGD(lr = 0.080),\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 24s 404us/sample - loss: 0.0896 - accuracy: 0.1492\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.0882 - accuracy: 0.2946\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 24s 407us/sample - loss: 0.0803 - accuracy: 0.4208\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 24s 402us/sample - loss: 0.0480 - accuracy: 0.6551\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 24s 407us/sample - loss: 0.0393 - accuracy: 0.7174\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 24s 407us/sample - loss: 0.0359 - accuracy: 0.7435\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 24s 402us/sample - loss: 0.0339 - accuracy: 0.7590\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 24s 402us/sample - loss: 0.0321 - accuracy: 0.7732\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 24s 403us/sample - loss: 0.0307 - accuracy: 0.7827\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 24s 403us/sample - loss: 0.0294 - accuracy: 0.7922\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 24s 403us/sample - loss: 0.0284 - accuracy: 0.8001\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 24s 404us/sample - loss: 0.0274 - accuracy: 0.8084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5d042ee08>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3.預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(n):\n",
    "    print('我的CNN預測是:', class_names[result[n]])\n",
    "    X = x_test[n].reshape(28,28)\n",
    "    plt.imshow(X, cmap = \"Greens\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我的CNN預測是: Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_predict(80) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2f62df7c0d4577ab29698619447216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='n', max=9999), Button(description='Run Interact', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_predict(n)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(my_predict, n = (0,9999)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 151us/sample - loss: 0.0276 - accuracy: 0.8064\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,acc = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的正確率: 0.8064\n"
     ]
    }
   ],
   "source": [
    "print(\"測試資料的正確率:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用不同數字再做一次看會有甚麼變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(12,(3,3),padding='same',input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(24, (3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(48, (3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立兩層Dense,神經元設為30,10\n",
    "model.add(Dense(40, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 24)        2616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 48)          10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 3, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 40)                17320     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 30,882\n",
      "Trainable params: 30,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.088),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 37s 617us/sample - loss: 0.0732 - accuracy: 0.4463\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 37s 609us/sample - loss: 0.0611 - accuracy: 0.5328\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 37s 617us/sample - loss: 0.0582 - accuracy: 0.5458\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.0566 - accuracy: 0.5540\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 37s 619us/sample - loss: 0.0554 - accuracy: 0.5610\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.0546 - accuracy: 0.5669\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 37s 619us/sample - loss: 0.0539 - accuracy: 0.5734\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 37s 621us/sample - loss: 0.0534 - accuracy: 0.5782\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 37s 622us/sample - loss: 0.0530 - accuracy: 0.5814\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 37s 620us/sample - loss: 0.0526 - accuracy: 0.5850\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 37s 619us/sample - loss: 0.0523 - accuracy: 0.5865\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 37s 622us/sample - loss: 0.0520 - accuracy: 0.5894\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 37s 620us/sample - loss: 0.0518 - accuracy: 0.5917\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 37s 618us/sample - loss: 0.0516 - accuracy: 0.5939\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 37s 619us/sample - loss: 0.0513 - accuracy: 0.5953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d5f1dd9748>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=120, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(n):\n",
    "    print('我的CNN預測是:', result[n])\n",
    "    X = x_test[n].reshape(28,28)\n",
    "    plt.imshow(X, cmap = \"Greens\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 258us/sample - loss: 0.0516 - accuracy: 0.5903\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,acc = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"測試資料的正確率:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把model儲存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myCNNmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "做三層channel filter改成12,24,48\n",
    "建立兩層Dense,神經元設為40,10\n",
    "把學習率改為0.088\n",
    "batch_size改為130, 訓練次數為15次\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
